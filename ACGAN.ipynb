{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e5d5b8-b911-47cf-ab4c-28a40fda26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision.utils as utils\n",
    "from IPython.display import HTML\n",
    "import time\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "from scipy import linalg\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as data_set\n",
    "import torchvision.transforms as transforms\n",
    "#from model import generator,discriminator\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision.utils as vutils\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc20aaaf-0ecd-414e-ba3d-5a55b3074bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class generator(nn.Module):\n",
    "\n",
    "    #generator model\n",
    "    def __init__(self,in_channels):\n",
    "        super(generator,self).__init__()\n",
    "        self.fc1=nn.Linear(in_channels,384)\n",
    "\n",
    "        self.t1=nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=384,out_channels=192,kernel_size=(4,4),stride=1,padding=0),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.t2=nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=192,out_channels=96,kernel_size=(4,4),stride=2,padding=1),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.t3=nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=96,out_channels=48,kernel_size=(4,4),stride=2,padding=1),\n",
    "            nn.BatchNorm2d(48),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.t4=nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=48,out_channels=3,kernel_size=(4,4),stride=2,padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=x.view(-1,110)\n",
    "        x=self.fc1(x)\n",
    "        x=x.view(-1,384,1,1)\n",
    "        x=self.t1(x)\n",
    "        x=self.t2(x)\n",
    "        x=self.t3(x)\n",
    "        x=self.t4(x)\n",
    "        return x #output of generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3307243c-8dc6-4b5b-9813-ba18e4dfe9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self,classes=10):\n",
    "        #we have 10 classes in the CIFAR dataset with 6000 images per class.\n",
    "        super(discriminator,self).__init__()\n",
    "        self.c1=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=16,kernel_size=(3,3),stride=2,padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5)\n",
    "            )\n",
    "        self.c2=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=(3,3),stride=1,padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5)\n",
    "            )\n",
    "        self.c3=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32,out_channels=64,kernel_size=(3,3),stride=2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5)\n",
    "            )\n",
    "        self.c4=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(3,3),stride=1,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5)\n",
    "            )\n",
    "        self.c5=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(3,3),stride=2,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5)\n",
    "            )\n",
    "        self.c6=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),stride=1,padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.5)\n",
    "            )\n",
    "        self.fc_source=nn.Linear(4*4*512,1)\n",
    "        self.fc_class=nn.Linear(4*4*512,classes)\n",
    "        self.sig=nn.Sigmoid()\n",
    "        self.soft=nn.Softmax()\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x=self.c1(x)\n",
    "        x=self.c2(x)\n",
    "        x=self.c3(x)\n",
    "        x=self.c4(x)\n",
    "        x=self.c5(x)\n",
    "        x=self.c6(x)\n",
    "        x=x.view(-1,4*4*512)\n",
    "        rf=self.sig(self.fc_source(x))#checks source of the data---i.e.--data generated(fake) or from training set(real)\n",
    "        c=self.soft(self.fc_class(x))#checks class(label) of data--i.e. to which label the data belongs in the CIFAR10 dataset\n",
    "        \n",
    "        return rf,c \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2139649-c9f3-4f28-8e39-b639c0c6e697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_scratch/pbs.530886.pbs02/ipykernel_3097206/179196832.py:58: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  c=self.soft(self.fc_class(x))#checks class(label) of data--i.e. to which label the data belongs in the CIFAR10 dataset\n"
     ]
    }
   ],
   "source": [
    "lr=0.0002\n",
    "epochs=5\n",
    "batch_size=100\n",
    "real_label = torch.FloatTensor(batch_size, 1).cuda()\n",
    "real_label.fill_(1)\n",
    "\n",
    "fake_label = torch.FloatTensor(batch_size, 1).cuda()\n",
    "fake_label.fill_(0)\n",
    "\n",
    "\n",
    "eval_noise = torch.FloatTensor(batch_size, 110, 1, 1).normal_(0, 1)\n",
    "eval_noise_ = np.random.normal(0, 1, (batch_size, 110))\n",
    "eval_label = np.random.randint(0, 10, batch_size)\n",
    "eval_onehot = np.zeros((batch_size, 10))\n",
    "eval_onehot[np.arange(batch_size), eval_label] = 1\n",
    "eval_noise_[np.arange(batch_size), :10] = eval_onehot[np.arange(batch_size)]\n",
    "eval_noise_ = (torch.from_numpy(eval_noise_))\n",
    "eval_noise.data.copy_(eval_noise_.view(batch_size, 110, 1, 1))\n",
    "eval_noise=eval_noise.cuda()\n",
    "\n",
    "\n",
    "def compute_acc(preds, labels):\n",
    "    correct = 0\n",
    "    preds_ = preds.data.max(1)[1]\n",
    "    correct = preds_.eq(labels.data).cpu().sum()\n",
    "    acc = float(correct) / float(len(labels.data)) * 100.0\n",
    "    return acc\n",
    "\n",
    "def weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1:\n",
    "            m.weight.data.normal_(0.0, 0.02)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "dataset = data_set.CIFAR10(\n",
    "                root='/home/ralluri/Deep-Learning/Homework3/dataset/CIFAR10data', download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.Resize((32,32)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                    ]))\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "gen=generator(110).cuda()\n",
    "disc=discriminator().cuda()\n",
    "\n",
    "gen.apply(weights_init)\n",
    "\n",
    "optimD=optim.Adam(disc.parameters(),lr)\n",
    "optimG=optim.Adam(gen.parameters(),lr)\n",
    "\n",
    "source_obj=nn.BCELoss()#source-loss\n",
    "\n",
    "class_obj=nn.NLLLoss()#class-loss\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i,data in enumerate(dataloader,0):\n",
    "        '''\n",
    "        At first we will train the discriminator\n",
    "        '''\n",
    "        #training with real data----\n",
    "        optimD.zero_grad()\n",
    "\n",
    "        image,label=data\n",
    "        image,label=image.cuda(),label.cuda()\n",
    "\n",
    "        source_,class_=disc(image)#we feed the real images into the discriminator\n",
    "        #print(source_.size())\n",
    "        #real_label = real_label.unsqueeze(1)\n",
    "        #torch_3d = torch.ones(100, 1)\n",
    "        #real_label = real_label.squeeze(torch_3d)\n",
    "        #print(source_.shape)\n",
    "        #print(real_label.shape)\n",
    "        source_error=source_obj(source_,real_label)#label for real images--1; for fake images--0\n",
    "        class_error=class_obj(class_,label)\n",
    "        error_real=source_error+class_error\n",
    "        error_real.backward()\n",
    "        optimD.step()\n",
    "\n",
    "\n",
    "        accuracy=compute_acc(class_,label)#getting the current classification accuracy\n",
    "\n",
    "        #training with fake data now----\n",
    "\n",
    "\n",
    "        noise_ = np.random.normal(0, 1, (batch_size, 110))#generating noise by random sampling from a normal distribution\n",
    "\n",
    "        label=np.random.randint(0,10,batch_size)#generating labels for the entire batch\n",
    "\n",
    "        noise=((torch.from_numpy(noise_)).float())\n",
    "        noise=noise.cuda()#converting to tensors in order to work with pytorch\n",
    "\n",
    "        label=((torch.from_numpy(label)).long())\n",
    "        label=label.cuda()#converting to tensors in order to work with pytorch\n",
    "\n",
    "        noise_image=gen(noise)\n",
    "        #print(noise_image.size())\n",
    "\n",
    "        source_,class_=disc(noise_image.detach())#we will be using this tensor later on\n",
    "        #print(source_.size())\n",
    "        #fake_label = fake_label.unsqueeze(1)\n",
    "        #torch_3d = torch.ones(100, 1)\n",
    "        #fake_label = fake_label.squeeze(torch_3d)\n",
    "        source_error=source_obj(source_,fake_label)#label for real images--1; for fake images--0\n",
    "        class_error=class_obj(class_,label)\n",
    "        error_fake=source_error+class_error\n",
    "        error_fake.backward()\n",
    "        optimD.step()\n",
    "\n",
    "\n",
    "        '''\n",
    "        Now we train the generator as we have finished updating weights of the discriminator\n",
    "        '''\n",
    "\n",
    "        gen.zero_grad()\n",
    "        source_,class_=disc(noise_image)\n",
    "        source_error=source_obj(source_,real_label)#The generator tries to pass its images as real---so we pass the images as real to the cost function\n",
    "        class_error=class_obj(class_,label)\n",
    "        error_gen=source_error+class_error\n",
    "        error_gen.backward()\n",
    "        optimG.step()\n",
    "        iteration_now = epoch * len(dataloader) + i\n",
    "\n",
    "\n",
    "        #print(\"Epoch--[{} / {}], Loss_Discriminator--[{}], Loss_Generator--[{}],Accuracy--[{}]\".format(epoch,epochs,error_fake,error_gen,accuracy))\n",
    "\n",
    "\n",
    "        '''Saving the images by the epochs'''\n",
    "        if i % 100 == 0:\n",
    "            constructed = gen(eval_noise)\n",
    "            vutils.save_image(\n",
    "                constructed.data,\n",
    "                '%s/results_epoch_%03d.png' % ('images/', epoch)\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bac74d-db9d-4572-8547-93e4dbacbc3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
